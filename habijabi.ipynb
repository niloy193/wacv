{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "import cv2\n",
    "import torchshow as ts\n",
    "from tqdm import tqdm\n",
    "from dataloader.loader import generator\n",
    "import yaml\n",
    "import utils.utils as ut\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "ut.set_random_seed(1221)\n",
    "with open('config/config.yaml', 'r') as file:\n",
    "    cfg = yaml.load(file, Loader=yaml.FullLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in validation_generator:\n",
    "    print(x[1].shape)\n",
    "    ts.show(x[1][0])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 5\n",
    "l =[1 for i in range(n)]\n",
    "print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import torch\n",
    "import segmentation_models_pytorch as smp\n",
    "from tqdm import tqdm\n",
    "import utils.utils as utils\n",
    "import torch.optim as optim\n",
    "from utils.utils import AverageMeter, batch_intersection_union, write_logger, set_random_seed\n",
    "import itertools\n",
    "from sklearn import metrics\n",
    "import datetime\n",
    "import timm\n",
    "import yaml\n",
    "\n",
    "set_random_seed(1441)\n",
    "\n",
    "with open('config/config.yaml', 'r') as file:\n",
    "    cfg = yaml.load(file, Loader=yaml.FullLoader)\n",
    "\n",
    "with torch.no_grad():\n",
    "    test_model = timm.create_model(cfg['model_params']['encoder'], pretrained= False, features_only=True, out_indices=[4])\n",
    "    in_planes = test_model(torch.randn((2,3,128,128)))[0].shape[1]\n",
    "    del test_model\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "\n",
    "from model.model import ConSegNet\n",
    "model = ConSegNet(cfg, in_planes).to(device)\n",
    "pretrained_params = []\n",
    "other_params = []\n",
    "for key in list(model.named_parameters()):\n",
    "    if len(key[0].split('encoder.')) == 2:\n",
    "        pretrained_params.append(key[1])\n",
    "    else:\n",
    "        other_params.append(key[1])\n",
    "\n",
    "\n",
    "if cfg['dataset_params']['dataset_name'] == 'caisa':\n",
    "    from dataloader.loader import generator\n",
    "elif cfg['dataset_params']['dataset_name'] == 'imd_2020':\n",
    "    from dataloader.loader_imd import generator\n",
    "\n",
    "\n",
    "gnr = generator(cfg)\n",
    "training_generator = gnr.get_train_generator()\n",
    "validation_generator = gnr.get_val_generator()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_list = ['encoder.']\n",
    "pretrained_params = []\n",
    "other_params = []\n",
    "for key in list(model.named_parameters()):\n",
    "    if len(key[0].split('encoder.')) == 2:\n",
    "        pretrained_params.append(key[1])\n",
    "    else:\n",
    "        other_params.append(key[1])\n",
    "    \n",
    "# params = list(filter(lambda kv: kv[0] in my_list, model.named_children()))\n",
    "# base_params = list(filter(lambda kv: kv[0] not in my_list, model.named_parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "optimizer = optim.SGD([{'params': pretrained_params, 'lr' : 1e-6}, \n",
    "            {'params': other_params}], \n",
    "            lr = cfg['model_params']['lr'], weight_decay = 1e-4, momentum = 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = '/home/agency/xai/forgery/IMD2020'\n",
    "all_files = os.listdir(root_dir)\n",
    "train_all_IDs = {}\n",
    "mask_all_IDs = {}\n",
    "count = 0\n",
    "for files in all_files:\n",
    "    all_file = os.listdir(os.path.join(root_dir,files))\n",
    "    for file_name in all_file:\n",
    "        if len(file_name.split('_0.jpg'))==2:\n",
    "            train_all_IDs[count] = files+'/'+file_name\n",
    "            mask_all_IDs[count] = files+'/'+file_name.split('_0.jpg')[0]+'_0_mask.png'\n",
    "            count +=1\n",
    "rand = np.random.choice(len(train_all_IDs), math.ceil(len(train_all_IDs)*0.1), replace=False).tolist()\n",
    "\n",
    "train_IDs = {}\n",
    "mask_IDs = {}\n",
    "test_IDs = {}\n",
    "mask_test_IDs = {}\n",
    "\n",
    "count = 0\n",
    "test_count = 0\n",
    "for i in range(len(train_all_IDs)):\n",
    "    if i in rand:\n",
    "        test_IDs[test_count] = os.path.join(root_dir,train_all_IDs[i])\n",
    "        mask_test_IDs[test_count] = os.path.join(root_dir,mask_all_IDs[i])\n",
    "        test_count += 1\n",
    "    else:\n",
    "        train_IDs[count] = os.path.join(root_dir,train_all_IDs[i])\n",
    "        mask_IDs[count] = os.path.join(root_dir,mask_all_IDs[i])\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(train_IDs)):\n",
    "    img = cv2.imread(test_IDs[i])\n",
    "    img = cv2.resize(img, (224,224))\n",
    "    img = torch.from_numpy(img)\n",
    "    ts.show(img)\n",
    "    mask = cv2.imread(mask_test_IDs[i])\n",
    "    mask = cv2.resize(mask, (224,224))\n",
    "    mask = torch.from_numpy(mask)\n",
    "    ts.show(mask)\n",
    "    if i==10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file_name in all_file:\n",
    "    print(file_name)\n",
    "    print(file_name.split('_0.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.mantranet import MantraNet\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "model=MantraNet(device=device).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ut.set_random_seed(1221)\n",
    "gnr = generator(cfg)\n",
    "train_gen = gnr.get_train_generator()\n",
    "val_gen = gnr.get_val_generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for img, mask in tqdm(val_gen):\n",
    "    out = model(img.cuda())\n",
    "    print(out.shape)\n",
    "    break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, predict = torch.max(out, 1)\n",
    "print(predict.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "from tqdm import tqdm\n",
    "for i in tqdm(range(len(casiav1_files))):\n",
    "    filename = casiav1_files[i].split('.')[0]\n",
    "    for j in range(len(casiav1_masks)):\n",
    "        mask_name = casiav1_masks[j].split('.')[0].split('_gt')[0]\n",
    "        if filename == mask_name:\n",
    "            f = open('/home/agency/xai/forgery/wacv/dataloader/casiav1_train.txt', \"a\")\n",
    "            f.write(casiav1_files[i] + \"\\n\")\n",
    "            f.close()\n",
    "            f = open('/home/agency/xai/forgery/wacv/dataloader/casiav1_mask.txt', \"a\")\n",
    "            f.write(casiav1_masks[j] + \"\\n\")\n",
    "            f.close()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(casiav1_masks[j])\n",
    "print(casiav1_files[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msk = cv2.imread('/home/agency/xai/forgery/CASIA1/Gt/Sp/Sp_D_NNN_R_cha0084_sec0061_0369_gt.png',0)\n",
    "msk.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('config/config.yaml', 'r') as file:\n",
    "    cfg = yaml.load(file, Loader=yaml.FullLoader)\n",
    "\n",
    "train = train_generator(cfg)\n",
    "val = val_generator(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = []\n",
    "a.append('none')\n",
    "a.append(2)\n",
    "print(a)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e470db166faf928c816a3c4594623f758f5f8b390569cb68da693a2d6ba357bd"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('xai')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
